%
%
\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}

\title{DRAFT: Social Learning and Shared Belief: The Importance of Bias and Trust for Information Diffusion}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}

We investigate the impact that bias and trust has on how information is diffused within a network of agents.  We use this model to investigate the information diffusion characteristics of 2 different data sets.  We also use our measures of trust to estimate some probability for the real state of the world.  Additionally, we estimate whether certain agents are higher quality than others based on how well they are trusted.  Finally, we consider a measure of risk aversion related to how willing agents are to trust each other.

\end{abstract}

\section{Introduction}

Individuals often rely on the information and decisions of other individuals and companies to inform their understanding about how the world works.  Consider the case two competing newspapers, firm A and B.  If firm A sees a report about corruption at City Hall from firm B, this may influence what firm A publishes the next day and where they dedicate their investigative resources.  This influence may be related to how much firm A trusts the reporting of firm B and how similar their beliefs about the world are.

We consider a general model of social learning, motivated by the above hypothetical, where agents learn from other agents in their network based on how much they trust the other agents.  We investigate the importance of this trust network to information diffusion and use it to help develop estimates of the actual state of the world and quality of different agents in the network. 

We examine two novel data sets to investigate this model, the first is a data set of tweets for a list of roughly 3000 media firms in the United States from June to August of 2014.  Additionally, we consider a data set of articles taken from the preprint repository ArXiv.  We build a trust network for both of these data sets based on a number of different measures of bias and use this to investigate our model. To investigate this model we use a graphical variant of the dynamic topic model to estimate trust between agents.

We consider 5 predictions.  First, firms that share common beliefs are more likely to trust each other.  Second, firms that share common beliefs will communicate information faster.  Third, higher quality firms are more likely to be trusted by all firms.  Fourth, information that originates from multiple distance media sources is more likely to be accurate.  Fifth, neutral media sources are important to the complete diffusion of information. 

The paper is grouped as follows.  Section 2 presents the prior literature.  Section 3 develops the model used throughout.  Section 4 covers the data sets used.  Section 5 covers the implementation of the model.  Section 6 presents the results.  Finally, Section 7 summarizes and concludes.

\section{Literature Review}

We draw heavily from Gentzkow and Shapiro's 2006 paper \emph{Media Bias and Reputation}\footnote{Gentzkow and Shapiro.  Media Bias and Reputation. 2006}.  Gentzkow and Shapiro develop a model where media firms bias their reporting to align with the beliefs of their market to maximize profits.  We generalize this model to a network of agents, where each agent learns from the actions of other agents in the network, as well as their own exogenous signals.

To estimate media bias we consider a number of different measures.  Groseclose and Milyo develop a measure that looks at the citations made by different media firms and how these coincide with the citations made by members of Congress\footnote{Groseclose and Milyo. A Measure of Media Bias. 2005.}.  Similarlly, Gentzkow and Shapiro develop a measure of media slant that uses the similarity between words used by different media outlets and members of Congress\footnote{Gentzkow and Shapiro.  What Drives Media Slant?  Evidence from U.S. Daily Newspaper. 2006.}.  Finally, Chiang and Knight develop a model of media bias that looks at endorsements made by media firms\footnote{Chiang and Knight.  Media Bias and Influence: Evidence from Newspaper Endorsements. 2011.}.

The literature on slant in academia is more limited than in the media case, perhaps because the impact is less apparent.  Much of the literature focuses on divisions of citation networks, though some look at text clustering including one example presented below.  Onder and Tervio look at the division of citation networks into "freshwater" and "saltwater" departments for economics.  They find that the division is very real and significant in a number of cases\footnote{Onder and Tervio.  Is Economics a House Divided?  Analysis of Citation Networks.  2014.}.

The key work we draw from in the social learning literature is Acemoglu et. al's 2011 paper \emph{Bayesian Learning in Social Networks}\footnote{Acemoglu, Dahleh, Lobel and Ozdaglar.  Bayesian Learning in Social Networks. 2011.}.  They develop a model of Bayesian social learning that is built around a stochastic network similar to the one we develop here.  They derive a number of general conclusions that are significant to this type of model. Acemoglu et. al's work on social learning in endogenous social networks is also significant as it mirrors the network structure we develop here\footnote{Acemoglu, Bimpikis and Ozdaglar.  Dynamic of Information Exchange in Endogenous Social Networks.  2013.}.  Non Bayesian approaches have also been considered in the literature including Jadbabaie et. al's work\footnote{Jadbabaie, Molavi, Sandroni and Tahbaz-Salehi.  Non-Bayesian Social Learning.  2012.}, though we don't follow that approach here.

There is a large literature on more general information diffusion.  Young provides a good overview of how the social learning methods, popular in economics, compare to those used in other fields\footnote{Young.  Innovation Diffusion in Heterogeneous Populations: Contagion, Social Influence and Social Learning.  2014.}.  Golub and Jackson study how homophily affects diffusion and learning in networks.  Their results are directly relevant to the work done here\footnote{Golub and Jackson.  How Homophily Affects Learning and Diffusion in Networks. 2009.}.
 Yang and Leskovec develop a general model of information diffusion in implicit networks.  This is significant here because the network structure for our model is implicit\footnote{Yang and Leskovec.  Modeling Information Diffusion in Implicit Networks.  2010.}.

The method we use to estimate our model has its roots in the topic modeling literature, in particular the idea of Latent Dirichlet Allocation (LDA), first proposed by Blei, Ng and Jordan\footnote{Blei, Ng, Jordan. Latent Dirichlet Allocation. 2003.}.  LDA is essentially a hierarchical model where it is assumed that each word in a document is drawn from some topic distribution that is drawn for each document.  Using this hierarchical model Blei, Ng and Jordan proposed a method to estimate the underlying topic distribution for a set of documents.  Since their seminal paper the literature has exploded with examples of topic models.  Blei provides a good survey of the methodology\footnote{Blei.  Probabilitic Topic Models. 2012}.

Two key variants that are important here are dynamic topic models and author topic models.  A combination of these ideas form the basis for the estimation procedure used in this paper.  Blei
and Lafferty introduce the idea of dynamic topic models to represent how topic may change over time\footnote{Blei and Lafferty.  Dynamic Topic Models. 2006}.  They assume that the underlying topic proportions are drawn from some multivariate normal distribution centered around the prior topic distribution.  Our approach is an application of this method.  Rosen-Zvi et. al present another important variant in the idea of author topic models\footnote{Rosen-Zvi, Griffiths, Steyvers, Smyth.  The Author-Topic Model for Authors and Documents. 2004.}.  Their model assumes that each author has some underlying preference for certain topics that can be used to cluster documents.  While we don't directly implement this procedure the idea of a biased view of topics tied to each author is important to our model.

A number of studies have used similar methods to investigate similar datasets to ours.  Hong and Davison investigate an author topic model in the Twitter context to determine how Twitter users cluster and share information\footnote{Hong and Davison. Empirical Study of Topic Modeling in Twitter. 2010.}.  Grant et. al develop an online approach to estimating topics in the Twitter search context\footnote{Grant, George, Jenneisch and Wilson. Online Topic Modeling for Real-time Twitter Search. 2011.}.  Zhao et. al use a topic model to compare Twitter media to traditional media sources\footnote{Zhao, Jiang, Weng, He, Lim, Yan and Li. 2011.}.  Finally, Blei and Lafferty use a correlated topic model to estimate correlation within the scientific community using an academic article data set similar to the one used here\footnote{Blei and Lafferty. A Correlated Topic Model of Science. 2007.}.

\section{Model}

The roots of our model lie the Gentzkow and Shapiro paper \emph{Media Bias and Reputation}.  For now we focus on the case used in their paper with a media firm and consumer.  The approach works just as well in the case of a general network of agents.  As with the Gentzkow and Shapiro model, we assume that there are two states of the world

\[S \in [L,R].\]

There are $N$ distinct populations that each make a decision

\[A_i \in [L, R].\]

The $i$th population will receive a positive payoff in the case that $A_i = S$ and a payoff of zero otherwise.  Each population has a prior belief about the state of the world

\[P_i^c(R) = \theta_i^c.\]

For each population there is a monopolist news firm that has a prior belief about the state of the world

\[P_i(R) = \theta_i.\]

Each news firm receives a signal about the state of the world

\[s_i \in[l, r]\]

and can report their signal (or a variation of their signal) to their population.  There is some probability $\lambda$ that a given news firm is high quality.  A high quality news firm is a news firm that receives a perfect signal of the world in each period, that is

\[p_i(l|L) = p_i(r|R) =1.\]

Alternatively, a firm can be a normal quality firm.  If this is the case than there is a probability $\pi_i$ that the firms receives a signal that aligns with the state of the world

\[p_i(l|L) = p_i(r|R) = \pi_i.\]

Each firm can publish a report based on their signal

\[\hat{s}_i \in [\hat{l}, \hat{r}].\]

Gentzkow and Shapiro show that the optimal strategy for a high quality firm is to always report the truth, that is

\[\hat{s}_i = s_i.\]

However, for the normal quality firm it may be better to lie.  Each firm can chose a strategy based on their signal

\[\sigma_{is}(\hat{s}) = p_i(\hat{s}|s).\]

For the remainder of this paper we constrain ourselves to the case where 

\[\sigma_{ir}(\hat{r}) > \sigma_{il}(\hat{l}).\]

Gentzkow and Shapiro show that, in the case where a consumer receives no exogenous signal about the state of the world, their posterior beliefs about the quality of their news provider is a strictly increasing function of the likelihood ratio

\[\frac{p(\hat{r}|\text{high}_i)}{p(\hat{r}|\text{normal}_i)}=\frac{\theta_i^c}{\theta_i^c[\sigma_r(\hat{r}_i) \pi_i + \sigma_l(\hat{r}_i)(1-\pi_i)] + (1 - \theta_c^i)[\sigma_r(\hat{r}_i)(1-\pi_i) + \sigma_l(\hat{l}_i)\pi_i]}\]

This suggests that the higher $\theta_i^c$, the more likely  a consumer will believe the $i$th firm is of high quality.  In equilibrium they show that the expected gain for publishing $\hat{r}$ is

\[\Delta(s)_i = (1 - \mu)\Delta^{nf}_i+\mu \Delta^f_i(s)\]

where

\[\Delta^{nf}_i =f(\lambda_i(\hat{r}, 0)) - f(\lambda_i(\hat{r}, 1)\]

and

\[\Delta^f_i(s) = \theta_i(s)[f(\lambda_i(\hat{r}, R)) - f(0)] - (1-\theta_i(s))[f(\lambda_i(\hat{l},L) - f(0)]\]

In the above, $\lambda_i(\hat{s},0)$ represents the consumers posterior belief about the quality of the $i$th firm in the case of no feedback and $\lambda_i(\hat{s},S)$ represents the consumers posterior belief about the quality of the $i$th firm in the case of feedback.  $\theta_i(s)$ is the $i$th firms posterior belief about the state of the world after receiving their signal $s_i$. Gentzkow and Shapiro show that under equilibrium conditions it is in a normal media firms interests to skew their reporting to align with the consumers priors about the state of the world, because their consumers are more likely to trust them in this case.
\subsection{Inter-Firm Trust}
  
We now consider the situations in which firms can learn from each other.  We assume that in equilibrium the $i$th firm publishes articles that align with their consumers priors, $\theta_i^c$ and that the firms priors should reflect this, so $\theta_i \approx \theta_i^c$.  $\theta_i$ can then be thought of as the proportion of news stories published by the $i$th firm that correspond to the $R$ state of the world.  So then over $T$ periods we would expect $\theta_iT$ reports to be $\hat{r}$.  

Let's now turn to the $j$th firm's beliefs about the quality of the $i$th firm over $T$ periods.  In each period, the $j$th firms beliefs should be
 
 \[p_j(\text{high}_i|\hat{\textbf{s}}_{it}) = \frac{p_j(\hat{\textbf{s}}_{it}|\text{high}_i)p_j(\text{high}_i)}{p_j(\hat{\textbf{s}}_{it})}\]

where $\hat{\textbf{s}}_{it}$ is a vector of the reports made by the $i$th firm as of period $t$.  Assuming that the beliefs follow the monotone likelihood ratio property we can show that

\[p_j(\text{high}_i|\hat{\textbf{s}}_{it}) = \frac{p_j(\text{high}_i)}{1 + \frac{p_j(\hat{\textbf{s}}_{it}|\text{normal}_i)}{p_j(\hat{\textbf{s}}_{it}|\text{high}_i)}}\]

This gives us the Gentzkow and Shapiro result that $p_j(\text{high}_i|\hat{\textbf{s}}_{it})$ is a strictly increasing function of $\frac{p_j(\hat{\textbf{s}}_{it}|\text{high}_i)}{p_j(\hat{\textbf{s}}_{it}|\text{normal}_i)}$.  Since the proportion of $\hat{\textbf{s}}_{it}$ that is $\hat{r}$ is an increasing function of $\theta_j$,  $p_j(\text{high}_i|\hat{\textbf{s}}_{it})$ is an decreasing function of $\theta_j - \theta_i$, that is, the more similar the $i$th firms beliefs are to those of the $j$th firm the more likely the $j$th firm is to believe the $i$th firm is high quality.

We can use this idea to represent how much different news firms trust each other.  We use this to help derive a number of bias-free measures of truth and quality that could be used to help understand how the media market works.  Throughout the remainder of this paper we will think of $p_j(\text{high}_i|\hat{\textbf{s}}_{it})$ as the probability that the $j$th firm will incorporate the $i$th firms report into their own report.

NOTE: I think the next two sections may be the most interesting but they still need a good deal of development.  I don't really know what to do with them.

\subsection{Estimating Bias-Free Truth}

Consider a case where you have $N$ firms, as before, however, each firm cannot observe the reports of the other firms.  Additionally, assume that you are a Bayesian agent observing all $N$ firms and you want to get some estimate of the actual state of the world.  You may have your prior belief about the state of the world

\[p(R) = \theta\]

Additionally, you have the reports for each of the $N$ firms as evidence.  Then what you might do is update your beliefs following Bayes rule
 
 \[p(R|\hat{\textbf{s}}) \propto p(\hat{s}_1|R)...p(\hat{s}_N|R)p(R)\]
 
 Unfortunately, this does not work in the case where firms can observe the reports of other firms, because it is possible you may observe duplicate information.  To account for this we need to account for how much firms trust each other and how likely they are to borrow information from other firms.  Fortunately, you have a measure of how much likely it is that each firm will incorporate the reports of another firm into their report, $p_j(\text{high}_i|\hat{\textbf{s}}_{it})$.  We could modify the above posterior to account for this, let $\gamma_ij$ represent $p_j(\text{high}_i|\hat{\textbf{s}}_{it})$
 
 \[p(R|\hat{\textbf{s}}) \propto (1-\gamma_{12})(1-\gamma_{13})...(1-\gamma_{1N})p(\hat{s}_1|R)...\]
 
 \[(1-\gamma_{N1})(1-\gamma_{N2})...(1-\gamma_{NN-1})p(\hat{s}_N|R)p(R)\]
 
 We propose that this may be used as a measure to estimate the actual truth of a given state of the world.
  One implication of this proposal is that we are more certain about the state of the world the more dispersed a set of signals are.  To see this consider a simple two agent case.

\[p(R|\hat{\textbf{s}}) \propto (1-\gamma_{12})p(\hat{s}_1|R)(1-\gamma_{21})p(\hat{s}_2|R)p(R)\]

In this case the more likely either firm trust the other ($\gamma_{12}$ is higher or $\gamma_{21}$ is higher), the lower $p(R|\hat{\textbf{s}})$.  That is that if two firms share a similar belief about the state of the world and report the same signal, this says less than if two firms that have different beliefs report the same signal.

\subsection{Estimating Bias-Free Quality}

Next we propose a measure of bias-free quality for a given agent.  One aspect of our model that has so far been ignored is the $j$th firm's prior beliefs about the quality of the $i$th firm. We could think of this prior as the equilibrium belief about the quality of the $i$th firm.  Since $\theta_i$ and $\theta_j$ are the equilibrium beliefs for each firm about the state of the world, a reasonable choice for $p_j(H_i)$ might be $\theta_{ij}$, where $\theta_{ij} = \theta_i - \theta_j$.
If we accept this prior we can then get an estimate for the likelihood function 
\[p_j(\hat{\textbf{s}}_i|\text{high}_i) = \frac{p_j(\text{high}_i|\hat{\textbf{s}}_i)}{p_j(\text{high}_i)} = \frac{\gamma_ij}{\theta_ij}\]

Using this measure we could then think like the Bayesian agent from the sub section above

\[p(\text{high}_i|\hat{\textbf{s}}_i) \propto p(\hat{\textbf{s}}_i|\text{high}_i)p(\text{high}_i)\]

\[= p_1(\hat{\textbf{s}}_i|\text{high}_i)p_2(\hat{\textbf{s}}_i|\text{high}_i)...p_N(\hat{\textbf{s}}_i|\text{high}_i)p(\text{high}_i)\]

\[= \frac{\gamma_{1i}}{\theta_{1i}}\frac{\gamma_{2i}}{\theta_{2i}}...\frac{\gamma_{Ni}}{\theta_{Ni}}p(\text{high}_i)\]

This would then suggest that our bias free estimate of quality would be an increasing function of the total trust in the $i$th firm, and a decreasing function of the shared beliefs with the $i$th firm.  The intuition behind this measure is that higher quality firms should be more trusted by all firms controlling for bias.

\subsection{The Significance of Border Cases}

Next we consider the possibility of border agents.  The intuition behind the idea for border agents is that they are agents who have a high enough $\gamma$ value for two different agents with rather low $\gamma$ values that they allow the communication of ideas between groups who otherwise would not communicate.  More formally, consider a network with 3 agents, $i$, $j$, and $k$.  If

\[\gamma_{ij}\gamma_{jk} > \gamma_{ik}\]

the $j$th agent is a border agent.  Border agents are important because they mean that given a lag two groups that otherwise would not receive the same information can receive the same information.

We consider what proportion of the population of firms are border agents and how much information passes through the border agents.  NOTE: This sub section may belong in a different section.

\subsection{Risk Averse News Firms}

Next we consider the possibility that there are risk averse media firms.  These are firms that are willing to pay a premium to avoid poor quality information, relative to other firms.  This premium may involve waiting longer to verify a report or only trusting higher quality firms.  We say that these firms are more likely to trust firms that have a higher quality level controlling for bias than less risk averse firms.  To estimate who the risk averse firms are we could assume the following relationship between trust, bias and bias-free quality

\[\gamma_{ij} = \beta_1 \theta_{ij} + \beta_2 p(\text{high}_j|\hat{\textbf{s}}_j)\]

Firms that are more risk averse should have a higher $\beta_2$ relative to the rest of the population of firms. NOTE: This may also fit better in a different section.

\section{Implementation}

In order to estimate the trust between agents we specify a variation on the Dynamic Topic Model proposed by Blei and Lafferty\footnote{Blei and Lafferty. Dynamic Topic Model. 2006.}.  Topic models are a set of hierarchical models that assume a latent "topic" underlying the choice of words in a collection of documents.  The classical model is Latent Dirichlet Allocation (LDA), proposed by Blei et al.\footnote{Blei, Ng and Jordan. Latent Dirichlet Allocation. 2003}.  Assume that you have a collection of documents $D$ where $D = \{\textbf{w}_1, \textbf{w}_2, ... \textbf{w}_m\}$.  Each $\textbf{w}_i$ is a document consisting of a set of words $w = \{w_1, w_2, ..., w_n\}$.  LDA specifies the following generating process for the collection of documents:

\[\theta \sim \text{Dir}(\alpha)\]

\[z_n \sim Mult(\theta)\]

\[\phi \sim Dir(\beta)\]

\[w_n \sim  Mult(\phi_z)\]

That is, $\theta$ is drawn from a Dirichlet distribution for each document,  $\phi$ is drawn from a Dirichlet distribution for each topic.  Then $z_n$ is drawn for each word in the document, and the word is from a Multinomial disttribution for the $\phi$ for the specified topic $z_n$.  $\beta$ is a probability matrix where $\beta_{ij} = p(w^j = 1|z^i =1)$.  What makes LDA particularly interesting among the class of clustering models is that topic parameter is sampled for each individual word, allowing for a mixture of topics within a document.  Ultimately LDA allows for the estimation of $\theta$, $\phi$ and $\textbf{z}$ which estimate the distribution of topics within a collection of documents.

Variants of LDA have seen a great deal of success for modeling the popularity of certain ideas within a collection of documents, in particular we focus on the Dynamic Topic Model.  Blei and Lafferty developed the Dynamic Topic Model to account for the changing distribution of topics over time.  It allowed for more accurate estimation when faced with a time series of documents.  The Dynamic Topic Model has a similar structure to LDA, however, it assumes time dependence for the $\alpha$ and $\beta$ parameters.

\[\alpha_t | \alpha_{t-1} \sim N(\alpha_{t-1}, \delta^2I)\]

\[\beta_t | \beta_{t-1} \sim N(\beta_{t-1}, \sigma^2I)\]

\[\theta \sim N(\alpha_t, a^2I)\]

\[\phi \sim N(\beta_t, b^2I)\]

\[z_{tn} \sim Mult(\pi(\theta))\]

\[w_{tn} \sim Mult(\pi(\phi_z)\]

This generation procedure allows the distribution of topics to change over time, accounting for shifts in the content of documents.  Such a model is important for the dataset we wish to use where topics are changing regularly.  We use a variant of the Dynamic Topic Model that allows for the distribution of $\alpha_{it}$ to be impacted by $\text{\boldmath$\alpha$}_{t-1}$.  Where $\text{\boldmath$\alpha$}_{t-1}$ is a vector of the $\alpha_{it-1}$ values.  That is we assume that the underlying topic distribution is ultimately effected by the topic distributions for other agents in a network of agents.  More formally we say that,

\[\alpha_{it} \sim N(\text{\boldmath$\alpha$}_{t-1}^T \gamma_i, \delta^2I)\]

$\gamma_i$ is an $N$ dimensional vector of weights for the $N$ agents for the $i$th agent.  That is, $\alpha_{it}$ is drawn from a weighted sum of the $\alpha$ values for each agent in the prior period.  $\gamma_i$ gives an estimate of the impact that each agent has on the topic distribution of the $i$th agent.  We use $\gamma_i$ to represent our trust value discussed above.  Unfortunately, this generating process does not have a conjugate form so we cannot using Gibbs sampling as used commonly with LDA.  Instead we must use a more complicated Metropolis Hastings algorithm to estimate $\gamma_i$.

\newpage
\appendix

\section{Full Conditionals}

\[p(\gamma_i | \mu, \xi^2) = N(\mu, \xi^2I)\]

\[p(\alpha_{it} | \text{\boldmath$\alpha$}_{t-1}. \gamma_i, \delta^2) = N(\text{\boldmath$\alpha$}^T_{t-1} \gamma_i, \delta^2I)\]

\[p(\beta_t | \beta_{t-1}, \sigma^2) = N(\beta_{t-1}, \sigma^2I)\]

\[p(\theta | \alpha_{it}, a^2) = N(\alpha_{it}, a^2I)\] 

\[p(\phi | \beta_t, b^2) = N(\beta_t, b^2I)\]

\[p(z| \theta) = Mult(\pi(\theta))\]

\[p(w | \phi, z) = Mult(\pi(\phi_z))\]

\[p(\theta, \phi, \gamma_i, \alpha_{it}, \beta_t, z | w) \propto p(w | \phi, z) p(\phi |  \beta_t, b^2)  p(z | \theta)  p(\beta_t | \beta_{t-1}, \sigma^2) p(\theta | \alpha_{it}, a^2) p(\alpha_{it} | \text{\boldmath$\alpha$}_{t-1}, \gamma_i, \delta^2) p(\gamma_i | \mu, xi^2)\]

\subsection{Posterior Specification for $z_{jit}$}

\[p(z_{jit} | w_{jit}, \theta_{it}, \phi_t) \propto p(z_{jit} = k | \theta_{it}) p(w_{jit} | z_{jit} = k, \phi_t)\]

\[= \frac{\theta_{it}^{I_{z_{jit}}=k}}{\sum_k \theta_{it}} \frac{\phi_{kt}^{I_{w_j}=v}}{\sum_v \phi_{kt}}\]

\subsection{Posterior Specification for $\beta_t$}

\[p(\beta_t | \phi, \beta_{t-1}, b^2, \sigma^2) \propto p(\phi | \beta_t) p(\beta_t | \beta_{t-1})\]

\[=  \prod_{k=1}^K N(\beta_t, b^2I) N(\beta_{t-1}, \sigma^2I)\]

\[\propto \exp{\left(\sum_{k=1}^K(\phi_k - \beta_{t})^T(\phi_k - \beta_{t}) + (\beta_{t} - \beta_{t-1})^T(\beta_{t} - \beta_{t-1})\right)}\]

Since this doesn't have a standard form we use Metropolis Hastings to estimate the full conditional.

\subsection{Posterior Specification for $\alpha_{it}$}

\[p(\alpha_{it} | \theta, \text{\boldmath$\alpha$}_{t-1}, \gamma_i, a^2, \delta^2) \propto p(\theta | \alpha_{it}) p(\alpha_t | \text{\boldmath$\alpha$}, \gamma_i)\]

\[= \prod_{d=1}^{D_i} N(\alpha_{it}, a^2I) N(\text{\boldmath$\alpha$}_{t-1}^T \gamma_i, \delta^2I)\]

\[\propto \exp{\left(\sum_{d=1}^{D_i}(\theta_d - \alpha_{it})^T(\theta_d - \alpha_{it}) + (\alpha_{it} - \text{\boldmath$\alpha$}_{t-1}^T \gamma_i)^T(\alpha_{it} - \text{\boldmath$\alpha$}_{t-1}^T \gamma_i)\right)}\]

Since this doesn't have a standard form we use Metropolis Hastings to estimate the full conditional.

\subsection{Posterior Specification for $\gamma_i$}

\[p(\gamma_i | \alpha_{it}, \text{\boldmath$\alpha$}_{t-1}, \mu, \xi^2) \propto p(\alpha_{it} | \text{\boldmath$\alpha$}_{t-1}, \gamma_i, \delta^2) p(\gamma_i | \mu, \xi^2)\]

\[= \prod_{t=2}^T N(\text{\boldmath$\alpha$}_{t-1}^T \gamma_i, \delta^2I)N(\mu, \xi^2)\]

\[\propto \exp{\left(\sum_{t=2}^T(\alpha_{it} - \text{\boldmath$\alpha$}_{t-1}^T \gamma_i)^T(\alpha_{it} - \text{\boldmath$\alpha$}_{t-1}^T \gamma_i) + (\gamma_i - \mu)^T(\gamma_i - \mu)\right)}\]

Since this doesn't have a standard form we use Metropolis Hastings to estimate the full conditional.

\subsection{Posterior Specification for $\theta_{it}$}

\[p(\theta_{it} | z, \alpha_{it}, \delta^2) \propto p(z | \theta_{it}) p(\theta_{it} | \alpha_{it}, \delta^2)\]

\[= \prod_{d=1}^D \prod_{j=1}^{J_d} Mult(\pi(\theta_{dit}))\prod_{d=1}^D N(\alpha_{it}, \delta^2I)\]

\[\propto \left(\prod_{d=1}^D \prod_{j=1}^{J_d} \frac{\theta_{dit}^{I_{z_j}=k}}{\sum_k \theta_{dit}}\right) \exp{\left(\sum_{d=1}^D(\theta_{dit} - \alpha_{it})^T(\theta_{dit} - \alpha_{it})\right)} \]

Since this doesn't have a standard form we use Metropolis Hastings to estimate the full conditional.

\subsection{Posterior Specification for $\phi_t$}

\[p(\phi_t | \beta_t, z, w, b^2) \propto p(w | \phi_t, z) p(\phi_t | \beta_t)\]

\[= \prod_{k=1}^K \prod_{j=1}^{J_k} Mult(\pi(\phi_{kt}))\prod_{k=1}^K N(\beta_t, b^2)\]

\[\propto \left(\prod_{k=1}^K \prod_{j=1}^{J_k} \frac{\phi_{kt}^{I_{w_j}=v}}{\sum_v \phi_{kt}}\right) \exp{\left(\sum_{k=1}^K(\phi_{kt} - \beta_t)^T(\phi_{kt} - \beta_t)\right)}\]

Since this doesn't have a standard form we use Metropolis Hastings to estimate the full conditional.

\end{document}
